{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Preparamos los archivos con los datos\n",
        "\n",
        ".."
      ],
      "metadata": {
        "id": "99RVso7iIPhc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDadBZ0ea4M0",
        "outputId": "5ba11236-88bf-4a39-cd46-2feeb977292f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "circulo_data_test.txt  circulo_data_training.txt  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat circulo.csv"
      ],
      "metadata": {
        "id": "JlB3wIuBcdxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 circulo_data_training.txt\n",
        "!echo \"-------\"\n",
        "!tail -5 circulo_data_training.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frau6QiTwZVG",
        "outputId": "157d0d4a-eda0-48d3-ef87-2ab1da52207f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grado,x,y,r\r\n",
            "0,1,0,1\r\n",
            "1,0.999847695,0.017452406,1\r\n",
            "2,0.999390827,0.034899497,1\r\n",
            "3,0.998629535,0.052335956,1\r\n",
            "-------\n",
            "356,3.291961366,-0.230196363,3.3\n",
            "357,3.295477465,-0.172708656,3.3\n",
            "358,3.297989729,-0.115168339,3.3\n",
            "359,3.299497394,-0.057592941,3.3\n",
            "360,3.3,-8.08598E-16,3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Creamos nuestro data loader que usaremos para entrenar el modelo\n",
        "class Datos(Dataset): #torch.utils.data.Dataset\n",
        "  def __init__(self, data):\n",
        "    self.angulo = []\n",
        "    self.radio = []\n",
        "    self.X = []\n",
        "    self.Y = []\n",
        "\n",
        "    #Cargamos el .txt y extraemos todos los datos por linea y separados los campos por coma\n",
        "    file1 = open(data, 'r') \n",
        "    Lines = file1.readlines()\n",
        "    dato_angulo = 0\n",
        "    dato_posX = 1\n",
        "    dato_posY = 2\n",
        "    dato_radio = 3\n",
        "\n",
        "    for line in Lines:\n",
        "      tmp_line = line.strip()\n",
        "      tmp_line = tmp_line.split(',')\n",
        "\n",
        "      angulo = tmp_line[dato_angulo]\n",
        "      radio = tmp_line[dato_radio]\n",
        "      if (angulo != 'grado' and radio == '1') :\n",
        "        angulo = float(tmp_line[dato_angulo])\n",
        "        posX = float(tmp_line[dato_posX])\n",
        "        posY = float(tmp_line[dato_posY])\n",
        "        radio = float(tmp_line[dato_radio])\n",
        "\n",
        "#      if (angulo != 'grado' and radio == '1') :\n",
        "        self.angulo.append(angulo)\n",
        "        self.radio.append(radio)\n",
        "        self.X.append(int(float(posX)*100))\n",
        "        self.Y.append(int(float(posY)*100))\n",
        "\n",
        "    file1.close() \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # uso: train_data[index]\n",
        "    if index < len(self.angulo):\n",
        "      X = torch.tensor(float(self.angulo[index]), dtype = torch.float32)\n",
        "      target = torch.tensor(float(self.Y[index]), dtype = torch.float32)\n",
        "      #return X, target\n",
        "      return int(self.angulo[index]), int(self.Y[index])\n",
        "      #return self.X[index].value, self.Y[index].value\n",
        "\n",
        "      #X = float(self.X[index])\n",
        "      #target = float(self.Y[index])\n",
        "      #return X, target\n",
        "    return int(0), int(0)\n",
        "\n",
        "  def __len__(self):\n",
        "    # uso: len(train_data)\n",
        "    return len(self.X)\n",
        "\n",
        "  def __str__(self):\n",
        "    # uso: print(train_data)\n",
        "    return f'el valor X:{self.X[33]} Y:{self.Y[33]} radio:{self.radio[33]} y ang:{self.angulo[33]}'\n",
        "\n",
        "  def __call__(self, index):\n",
        "    # uso: train_data(index)\n",
        "    if index < len(self.X):\n",
        "       return self.X[index], self.Y[index]\n",
        "    return 0, 0"
      ],
      "metadata": {
        "id": "02DDw3QWg_a-"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "-xkNaZX9sh5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Instanciamos nuestros data loaders tanto para el entrenamiento como para la evaluacion\n",
        "train_data = Datos('circulo_data_training.txt')\n",
        "val_data = Datos('circulo_data_test.txt')\n",
        "###32\n",
        "train_set = DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "val_set = DataLoader(val_data, batch_size=1, shuffle=True)\n",
        "\n",
        "#train_loader = torch.utils.data.DataLoader(train_data, batch_size=6, shuffle=True, collate_fn=collate)\n",
        "#val_loader = torch.utils.data.DataLoader(val_data, batch_size=6, shuffle=True, collate_fn=collate)"
      ],
      "metadata": {
        "id": "PZN7M4Pkg3Nv"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data):\n",
        "  plt.plot(train_data[])"
      ],
      "metadata": {
        "id": "R63xbDWE0Wii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos pruebas con el DataSet y datos cargados\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "dCM26peuRE1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChGTtgOHvqFe",
        "outputId": "653fbffc-3fd3-4a31-bac3-aa4012aa324d"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb2HraRpswrx",
        "outputId": "ebe64acf-a2ae-44d9-f6c5-ec64903039ae"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el valor X:73 Y:68 radio:1.0 y ang:43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[33])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La9h_7Mv8zAr",
        "outputId": "9eac8185-a2bb-49ad-f197-9414a91e7ee8"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43, 68)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.angulo[33])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0zL5Q8N89Ia",
        "outputId": "3b95beb9-46da-47d3-9c72-774f76e28a4e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrBzR7-14OTX",
        "outputId": "38ac461f-17e5-4ffd-fa95-b22153eee5cc"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Datos at 0x7feab1627050>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[33]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0-3s7dn1R7N",
        "outputId": "760aa1b2-0e88-4bca-ccc3-43678936061e"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43, 68)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data(33)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_qBDe--5egN",
        "outputId": "b38cf54b-bc4b-4c7a-b2c6-fe05bff38456"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73, 68)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.angulo[33]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8qrnj599qUQ",
        "outputId": "6514f6d2-cc26-4917-ec15-b8daea071a72"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.0"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos pruebas con el DataLoader\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "h-b3ZXplQ_8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0hc5DCiRKGp",
        "outputId": "fe37adb4-e19d-48e5-a1f1-212f5d61413e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7feb3e5bda50>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " for x, target in train_set:\n",
        "    print (x, target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd8XnG96JlzW",
        "outputId": "dbe527fe-accc-40e9-b710-4f08cec5c772"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 28, 342,  29, 143]) tensor([ 46, -30,  48,  60])\n",
            "tensor([134, 224,  31, 141]) tensor([ 71, -69,  51,  62])\n",
            "tensor([358,  49, 267,   3]) tensor([ -3,  75, -99,   5])\n",
            "tensor([165, 234, 184, 154]) tensor([ 25, -80,  -6,  43])\n",
            "tensor([  0,  62, 281, 169]) tensor([  0,  88, -98,  19])\n",
            "tensor([312, 284, 136, 160]) tensor([-74, -97,  69,  34])\n",
            "tensor([354,  46, 222, 233]) tensor([-10,  71, -66, -79])\n",
            "tensor([215, 318,  33, 100]) tensor([-57, -66,  54,  98])\n",
            "tensor([272, 228, 173, 178]) tensor([-99, -74,  12,   3])\n",
            "tensor([270, 310, 147,  39]) tensor([-100,  -76,   54,   62])\n",
            "tensor([ 10, 149, 210,  43]) tensor([ 17,  51, -50,  68])\n",
            "tensor([142, 307,  47,   6]) tensor([ 61, -79,  73,  10])\n",
            "tensor([ 44, 300,  12, 347]) tensor([ 69, -86,  20, -22])\n",
            "tensor([ 69, 243,   4, 144]) tensor([ 93, -89,   6,  58])\n",
            "tensor([158, 171, 235, 309]) tensor([ 37,  15, -81, -77])\n",
            "tensor([133, 289, 219, 339]) tensor([ 73, -94, -62, -35])\n",
            "tensor([ 61, 350, 357, 242]) tensor([ 87, -17,  -5, -88])\n",
            "tensor([349, 139, 352,  40]) tensor([-19,  65, -13,  64])\n",
            "tensor([314, 355,  99, 175]) tensor([-71,  -8,  98,   8])\n",
            "tensor([317, 163, 209, 168]) tensor([-68,  29, -48,  20])\n",
            "tensor([227,  96, 238,  45]) tensor([-73,  99, -84,  70])\n",
            "tensor([103, 274,  93,  41]) tensor([ 97, -99,  99,  65])\n",
            "tensor([148,   2, 338,  97]) tensor([ 52,   3, -37,  99])\n",
            "tensor([223, 176, 109, 291]) tensor([-68,   6,  94, -93])\n",
            "tensor([132, 230, 213, 304]) tensor([ 74, -76, -54, -82])\n",
            "tensor([299,   1, 316, 279]) tensor([-87,   1, -69, -98])\n",
            "tensor([271, 351, 293, 294]) tensor([-99, -15, -92, -91])\n",
            "tensor([ 35, 180, 111, 348]) tensor([ 57,   0,  93, -20])\n",
            "tensor([266,  64, 214,  27]) tensor([-99,  89, -55,  45])\n",
            "tensor([290, 277, 237, 161]) tensor([-93, -99, -83,  32])\n",
            "tensor([313, 153,  98,  72]) tensor([-73,  45,  99,  95])\n",
            "tensor([ 67, 157, 182,  11]) tensor([92, 39, -3, 19])\n",
            "tensor([146,  38,  65, 110]) tensor([55, 61, 90, 93])\n",
            "tensor([ 59, 236, 303, 217]) tensor([ 85, -82, -83, -60])\n",
            "tensor([308,  32, 356, 295]) tensor([-78,  52,  -6, -90])\n",
            "tensor([150, 287,  73, 269]) tensor([ 50, -95,  95, -99])\n",
            "tensor([ 71, 101, 105, 297]) tensor([ 94,  98,  96, -89])\n",
            "tensor([104,  94, 183, 273]) tensor([ 97,  99,  -5, -99])\n",
            "tensor([298, 135, 311, 345]) tensor([-88,  70, -75, -25])\n",
            "tensor([172, 208,   5, 282]) tensor([ 13, -46,   8, -97])\n",
            "tensor([346, 177, 225, 241]) tensor([-24,   5, -70, -87])\n",
            "tensor([151, 231,  13, 167]) tensor([ 48, -77,  22,  22])\n",
            "tensor([ 37, 145, 156, 292]) tensor([ 60,  57,  40, -92])\n",
            "tensor([315, 220, 276, 337]) tensor([-70, -64, -99, -39])\n",
            "tensor([140,  95, 102, 162]) tensor([64, 99, 97, 30])\n",
            "tensor([275, 360,  25,  26]) tensor([-99,   0,  42,  43])\n",
            "tensor([278, 166, 353, 138]) tensor([-99,  24, -12,  66])\n",
            "tensor([343, 306,  24, 285]) tensor([-29, -80,  40, -96])\n",
            "tensor([216, 302, 232, 340]) tensor([-58, -84, -78, -34])\n",
            "tensor([159,   9, 137,  30]) tensor([35, 15, 68, 50])\n",
            "tensor([ 68, 181, 221, 288]) tensor([ 92,  -1, -65, -95])\n",
            "tensor([ 34,  63, 268, 152]) tensor([ 55,  89, -99,  46])\n",
            "tensor([319, 229, 218, 341]) tensor([-65, -75, -61, -32])\n",
            "tensor([320, 239, 226, 174]) tensor([-64, -85, -71,  10])\n",
            "tensor([106,  48, 344,  42]) tensor([ 96,  74, -27,  66])\n",
            "tensor([280, 301, 265, 211]) tensor([-98, -85, -99, -51])\n",
            "tensor([179,  36,   8, 155]) tensor([ 1, 58, 13, 42])\n",
            "tensor([ 66, 359,   7, 212]) tensor([ 91,  -1,  12, -52])\n",
            "tensor([286, 108,  60, 170]) tensor([-96,  95,  86,  17])\n",
            "tensor([ 70, 283, 164, 240]) tensor([ 93, -97,  27, -86])\n",
            "tensor([296, 107, 305]) tensor([-89,  95, -81])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enumerate(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V0LKJFnTrMi",
        "outputId": "91c87ce2-3620-4d51-d94e-5ffc356586c9"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<enumerate at 0x7feab16303c0>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n_batch, (x, target) in enumerate(train_set):\n",
        "    #x.reshape(1,32)\n",
        "    print('\\n Batch:{} Input:{} Label:{}'.format(n_batch, x.shape, target.shape), end=\"\")   #\\r para reset\n",
        "    print('\\n{}   {}'.format(x   , target))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQRRDnekSGiW",
        "outputId": "b5c636c9-3edb-4970-b9f0-ee855bc03cd7"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Batch:0 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([338, 312,  29,  49])   tensor([-37, -74,  48,  75])\n",
            "\n",
            " Batch:1 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 71, 152,  42,  10])   tensor([94, 46, 66, 17])\n",
            "\n",
            " Batch:2 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([276, 343,  27, 305])   tensor([-99, -29,  45, -81])\n",
            "\n",
            " Batch:3 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 72, 104, 274, 155])   tensor([ 95,  97, -99,  42])\n",
            "\n",
            " Batch:4 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([265, 225, 141, 342])   tensor([-99, -70,  62, -30])\n",
            "\n",
            " Batch:5 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([300, 243,  98, 162])   tensor([-86, -89,  99,  30])\n",
            "\n",
            " Batch:6 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([355, 153, 143, 273])   tensor([ -8,  45,  60, -99])\n",
            "\n",
            " Batch:7 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([314,   6,  12, 285])   tensor([-71,  10,  20, -96])\n",
            "\n",
            " Batch:8 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([137, 211,  34, 229])   tensor([ 68, -51,  55, -75])\n",
            "\n",
            " Batch:9 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 44, 144, 236, 271])   tensor([ 69,  58, -82, -99])\n",
            "\n",
            " Batch:10 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([216,  32,  66, 212])   tensor([-58,  52,  91, -52])\n",
            "\n",
            " Batch:11 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([  5,  45, 302, 145])   tensor([  8,  70, -84,  57])\n",
            "\n",
            " Batch:12 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([282, 292, 270, 290])   tensor([ -97,  -92, -100,  -93])\n",
            "\n",
            " Batch:13 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([179, 209,   2,  25])   tensor([  1, -48,   3,  42])\n",
            "\n",
            " Batch:14 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([340, 311,  11, 178])   tensor([-34, -75,  19,   3])\n",
            "\n",
            " Batch:15 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([170, 173,  38,  24])   tensor([17, 12, 61, 40])\n",
            "\n",
            " Batch:16 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([350,  69, 151,  95])   tensor([-17,  93,  48,  99])\n",
            "\n",
            " Batch:17 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([172, 213,  13, 111])   tensor([ 13, -54,  22,  93])\n",
            "\n",
            " Batch:18 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 67, 105, 222, 354])   tensor([ 92,  96, -66, -10])\n",
            "\n",
            " Batch:19 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 46,  28, 218, 313])   tensor([ 71,  46, -61, -73])\n",
            "\n",
            " Batch:20 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([275, 171, 345, 307])   tensor([-99,  15, -25, -79])\n",
            "\n",
            " Batch:21 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([149, 298,  37, 284])   tensor([ 51, -88,  60, -97])\n",
            "\n",
            " Batch:22 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([169, 184, 341, 210])   tensor([ 19,  -6, -32, -50])\n",
            "\n",
            " Batch:23 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([150, 165,   0, 156])   tensor([50, 25,  0, 40])\n",
            "\n",
            " Batch:24 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([238,  94, 239, 219])   tensor([-84,  99, -85, -62])\n",
            "\n",
            " Batch:25 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([308,  47, 224, 154])   tensor([-78,  73, -69,  43])\n",
            "\n",
            " Batch:26 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([339, 101, 132, 100])   tensor([-35,  98,  74,  98])\n",
            "\n",
            " Batch:27 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([163, 318, 288, 301])   tensor([ 29, -66, -95, -85])\n",
            "\n",
            " Batch:28 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([269, 267, 175,   1])   tensor([-99, -99,   8,   1])\n",
            "\n",
            " Batch:29 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([281, 358,  93, 166])   tensor([-98,  -3,  99,  24])\n",
            "\n",
            " Batch:30 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([315, 106, 136,  60])   tensor([-70,  96,  69,  86])\n",
            "\n",
            " Batch:31 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([356,  30, 337, 168])   tensor([ -6,  50, -39,  20])\n",
            "\n",
            " Batch:32 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([164,  31, 268, 103])   tensor([ 27,  51, -99,  97])\n",
            "\n",
            " Batch:33 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([102, 167, 303, 296])   tensor([ 97,  22, -83, -89])\n",
            "\n",
            " Batch:34 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 48, 176, 287, 310])   tensor([ 74,   6, -95, -76])\n",
            "\n",
            " Batch:35 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([233,  41,  36,  63])   tensor([-79,  65,  58,  89])\n",
            "\n",
            " Batch:36 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([299, 235,  62, 208])   tensor([-87, -81,  88, -46])\n",
            "\n",
            " Batch:37 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([272, 237, 182, 220])   tensor([-99, -83,  -3, -64])\n",
            "\n",
            " Batch:38 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 97, 228, 349, 181])   tensor([ 99, -74, -19,  -1])\n",
            "\n",
            " Batch:39 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([286, 291, 348, 346])   tensor([-96, -93, -20, -24])\n",
            "\n",
            " Batch:40 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 26, 140, 289, 278])   tensor([ 43,  64, -94, -99])\n",
            "\n",
            " Batch:41 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([110, 344, 297,  40])   tensor([ 93, -27, -89,  64])\n",
            "\n",
            " Batch:42 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([317, 293, 221, 309])   tensor([-68, -92, -65, -77])\n",
            "\n",
            " Batch:43 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([352, 306, 283,  43])   tensor([-13, -80, -97,  68])\n",
            "\n",
            " Batch:44 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([159, 351, 353, 223])   tensor([ 35, -15, -12, -68])\n",
            "\n",
            " Batch:45 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([232, 134, 158,   7])   tensor([-78,  71,  37,  12])\n",
            "\n",
            " Batch:46 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 35,  96, 142, 294])   tensor([ 57,  99,  61, -91])\n",
            "\n",
            " Batch:47 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([295, 320, 357, 266])   tensor([-90, -64,  -5, -99])\n",
            "\n",
            " Batch:48 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([347,  99, 107, 108])   tensor([-22,  98,  95,  95])\n",
            "\n",
            " Batch:49 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([231, 160, 146,  39])   tensor([-77,  34,  55,  62])\n",
            "\n",
            " Batch:50 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([217,  73, 242, 214])   tensor([-60,  95, -88, -55])\n",
            "\n",
            " Batch:51 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([148, 280, 109,  59])   tensor([ 52, -98,  94,  85])\n",
            "\n",
            " Batch:52 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([157, 319, 277,  33])   tensor([ 39, -65, -99,  54])\n",
            "\n",
            " Batch:53 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([226, 241,  70, 174])   tensor([-71, -87,  93,  10])\n",
            "\n",
            " Batch:54 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([147, 240, 135, 316])   tensor([ 54, -86,  70, -69])\n",
            "\n",
            " Batch:55 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([  9, 177,   4,  61])   tensor([15,  5,  6, 87])\n",
            "\n",
            " Batch:56 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([230, 161, 133, 138])   tensor([-76,  32,  73,  66])\n",
            "\n",
            " Batch:57 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([360,   8, 215, 139])   tensor([  0,  13, -57,  65])\n",
            "\n",
            " Batch:58 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([ 65,   3, 227, 234])   tensor([ 90,   5, -73, -80])\n",
            "\n",
            " Batch:59 Input:torch.Size([4]) Label:torch.Size([4])\n",
            "tensor([359, 180, 279,  68])   tensor([ -1,   0, -98,  92])\n",
            "\n",
            " Batch:60 Input:torch.Size([3]) Label:torch.Size([3])\n",
            "tensor([ 64, 183, 304])   tensor([ 89,  -5, -82])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos pruebas para el Modelo\n",
        "\n",
        ".."
      ],
      "metadata": {
        "id": "XU2Pj_FcIYvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU, Sigmoid, Sequential, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
        "\n",
        "tensor_prueba = torch.randn((3,5))\n",
        "print(tensor_prueba, tensor_prueba.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx8us7tZmrXQ",
        "outputId": "159b3bf8-236a-4acb-9c5c-612186843f27"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2900,  0.0610, -1.3732,  0.7854, -0.7471],\n",
            "        [-0.7236, -2.4063, -0.0147,  0.1474, -1.4075],\n",
            "        [ 2.3376, -1.1431, -1.3865,  0.3242,  0.4374]]) torch.Size([3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "capa_lineal = Linear(5,8)\n",
        "tensor_nuevo = capa_lineal(tensor_prueba)\n",
        "print(tensor_nuevo, tensor_nuevo.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ92a5dRof1C",
        "outputId": "7f3ce010-ca23-456b-e422-718e2c6a6251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0441, -0.2837, -0.6494, -0.6219, -0.8610,  0.3008,  0.1415,  0.2727],\n",
            "        [ 0.5384,  0.1464, -1.1276,  0.0139, -0.4887, -0.1573, -0.1056,  0.6300],\n",
            "        [-0.3258, -0.8278, -0.4613, -0.5212, -0.9913, -0.9906, -0.0339, -0.5147]],\n",
            "       grad_fn=<AddmmBackward0>) torch.Size([3, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result: solo los positivos pasan, los neg quedan en cero\n",
        "#funcion de activacion\n",
        "relu = ReLU()\n",
        "print(tensor_prueba, tensor_prueba.shape)\n",
        "print(relu(tensor_prueba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-leYjJ_pHDZ",
        "outputId": "f3867b35-34d3-4035-bd26-618cebb0b7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5645,  0.6208,  0.4675,  0.4056,  0.2979],\n",
            "        [ 1.3424,  0.2227, -0.2513, -0.5483,  0.3253],\n",
            "        [-0.8243,  1.8914,  0.0777, -1.0353, -0.2980]]) torch.Size([3, 5])\n",
            "tensor([[0.5645, 0.6208, 0.4675, 0.4056, 0.2979],\n",
            "        [1.3424, 0.2227, 0.0000, 0.0000, 0.3253],\n",
            "        [0.0000, 1.8914, 0.0777, 0.0000, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result: numeros entre 0 y 1\n",
        "#funcion de activacion\n",
        "sigm = Sigmoid()\n",
        "print(tensor_prueba)\n",
        "print(sigm(tensor_prueba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZEP_36JpqDv",
        "outputId": "c6df53df-43ef-4cc9-f11a-4826b031e223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5645,  0.6208,  0.4675,  0.4056,  0.2979],\n",
            "        [ 1.3424,  0.2227, -0.2513, -0.5483,  0.3253],\n",
            "        [-0.8243,  1.8914,  0.0777, -1.0353, -0.2980]])\n",
            "tensor([[0.6375, 0.6504, 0.6148, 0.6000, 0.5739],\n",
            "        [0.7929, 0.5554, 0.4375, 0.3663, 0.5806],\n",
            "        [0.3049, 0.8689, 0.5194, 0.2621, 0.4261]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result: pondera y la suma del tensor (fila) dara 1\n",
        "# se usa previo a la capa final o post a la de resultado\n",
        "soft = Softmax(dim=1)\n",
        "print(soft(tensor_prueba))\n",
        "print(soft(tensor_prueba).sum(dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE1futBnp3Rj",
        "outputId": "cd27e78f-56f4-436b-c853-af164b979f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2181, 0.2308, 0.1980, 0.1861, 0.1671],\n",
            "        [0.4897, 0.1598, 0.0995, 0.0739, 0.1771],\n",
            "        [0.0474, 0.7170, 0.1169, 0.0384, 0.0803]])\n",
            "tensor([1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#agrup varios pasos\n",
        "seq = Sequential(capa_lineal, relu, soft)\n",
        "tensor_final = seq(tensor_prueba)\n",
        "print(tensor_final, tensor_final.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIiOZdeNrIo5",
        "outputId": "da9818b9-6ae0-4a46-f422-dbf11c4cb689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1134, 0.1134, 0.1134, 0.1134, 0.1134, 0.1532, 0.1307, 0.1490],\n",
            "        [0.1755, 0.1186, 0.1024, 0.1039, 0.1024, 0.1024, 0.1024, 0.1923],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],\n",
            "       grad_fn=<SoftmaxBackward0>) torch.Size([3, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apaga neuronas, dejando puntos en cero, segun la probabilidad p=0.15\n",
        "drop = Dropout(p=0.15)\n",
        "print(drop(tensor_prueba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA2SNg1Trrxe",
        "outputId": "bcce0fe3-104c-4086-c1eb-24450c128953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.7304,  0.0000,  0.4772,  0.3504],\n",
            "        [ 1.5793,  0.2620, -0.2956, -0.6451,  0.3827],\n",
            "        [-0.9697,  2.2252,  0.0914, -1.2180, -0.3506]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#resultado: similar a softmax, modifica los valores para alcanzar una varianza 1, y media 0, aplicando un tensor con valores imprimibles\n",
        "#lleva los valores a un rango negativo y positivo numeros incluso grandes\n",
        "tensor_lineal = 100*torch.randn((3,5))\n",
        "bn = BatchNorm1d(5, momentum=None)\n",
        "tensor_bn= bn(tensor_lineal)\n",
        "print(tensor_bn, tensor_bn.shape)\n",
        "print(tensor_bn.mean(dim=[0]), '\\n', tensor_bn.var(dim=[0], unbiased=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6mu7eSPstfv",
        "outputId": "2dba6560-394b-4930-a9e2-c9bbfd6ce8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0447, -1.0230,  0.1806,  1.3499,  0.6368],\n",
            "        [-1.2018,  1.3571,  1.1244, -0.3099, -1.4120],\n",
            "        [ 1.2465, -0.3341, -1.3050, -1.0400,  0.7751]],\n",
            "       grad_fn=<NativeBatchNormBackward0>) torch.Size([3, 5])\n",
            "tensor([ 7.9473e-08,  9.9341e-09,  0.0000e+00, -7.9473e-08,  0.0000e+00],\n",
            "       grad_fn=<MeanBackward1>) \n",
            " tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n, p in bn.named_parameters():\n",
        "     print(n,p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tslRmxfvm6i",
        "outputId": "48f51ea4-d788-4f8a-b62b-e164854a94cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos con el Modelo\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "LjSmAlswFnZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n"
      ],
      "metadata": {
        "id": "SkFSheEm8Wp0"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kukbkEt58Ln3",
        "outputId": "d54132a1-2c06-4456-cf3b-ee053ea94984"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RedNeuronal(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(RedNeuronal, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "                    nn.Linear(1, 4)\n",
        "                    ,nn.Sigmoid()\n",
        "                    )\n",
        "  \n",
        "    self.fc2s = nn.Sequential(\n",
        "                    nn.Linear(4, 4)\n",
        "                    ,nn.Sigmoid()\n",
        "                    )\n",
        "\n",
        "    self.fc2r = nn.Sequential(\n",
        "                    nn.Linear(4, 4)\n",
        "                    ,nn.ReLU()\n",
        "                    )\n",
        "\n",
        "    self.fc3 = nn.Sequential(\n",
        "                    nn.Linear(4, 1)\n",
        "                    ,nn.Sigmoid()\n",
        "                    )\n",
        "\n",
        "  def forward(self, entrada):\n",
        "     x = self.fc1(entrada)\n",
        "     x = self.fc2s(x)\n",
        "     x = self.fc2r(x)\n",
        "     x = self.fc2s(x)\n",
        "     x = self.fc2r(x)\n",
        "     x = self.fc3(x)\n",
        "     return x  #self.model(x)"
      ],
      "metadata": {
        "id": "kjKVlh8zFgsI"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam #SGD\n",
        "#optimizer = SGD(RedNeuronal.parameters())\n",
        "\n",
        "model = RedNeuronal()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "eaG_8ce6U-5b"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "#loss_fnc = CrossEntropyLoss()\n",
        "\n",
        "loss_fnc = nn.MSELoss()"
      ],
      "metadata": {
        "id": "JAODbfCtUnF0"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 100\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, n_epoch +1):\n",
        "  total_correctas = 0.0\n",
        "  total_muestras = 0.0\n",
        "\n",
        "  for i_batch, (x, target) in enumerate(train_set):\n",
        "  #for x, target in train_set:\n",
        "    optimizer.zero_grad()\n",
        "    output = model(x)\n",
        "\n",
        "    loss = loss_fnc(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    preds = output[output.argmax()] #dim=1)\n",
        "    correctas = (preds == target).sum()\n",
        "    total_correctas += correctas\n",
        "    total_muestras += target.shape[0]\n",
        "\n",
        "    accuracy = total_correctas / total_muestras\n",
        "\n",
        "    print('\\nEpoca:{} Loss:{:.2f}% Cor/Tot:{}/{} Accur:{:.2f}% X/Y/O:{}{}{}'.format(epoch, loss, total_correctas, total_muestras, 100*accuracy, x, target, output[0]), end='')\n",
        "\n",
        "  print('\\r')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "zI5QP-wfYEcU",
        "outputId": "89297128-3900-48a6-a932-87a04b961b26"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-63f81b7f0c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#for x, target in train_set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-157-04c3b394d866>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, entrada)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentrada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x4 and 1x4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n44nb1FpVFug",
        "outputId": "9b5a48b1-14e1-4443-c939-8f1a66f66c4b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th\n",
        "a = 0\n",
        "c=th.tensor([5,2,3,4])\n",
        "d=th.tensor([1,2,3])\n",
        "a=c[c.argmax()]\n",
        "#a = (c == d).sum()\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoFkcmxGQfRp",
        "outputId": "c58688b4-1fc0-4ee0-ea88-dfa81b627645"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPA6Cu_VnzTY",
        "outputId": "6d35333b-d3ed-4412-aaf9-7e92a4b9b135"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0049], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tempX = torch.tensor(float(90), dtype = torch.float32)\n",
        "tempX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAK1DC4YOTOz",
        "outputId": "a633017a-1e73-4357-f149-da5cb5d91a1c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(90.)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(tempX)"
      ],
      "metadata": {
        "id": "Q1o392onod9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 1\n",
        "#model.train()\n",
        "for epoch in range(1, n_epoch +1):\n",
        "  total_correctas = 0.0\n",
        "  total_muestras = 0.0\n",
        "\n",
        "  #for i_batch, (x, target) in enumerate(train_set):\n",
        "  for x, target in val_set:\n",
        "#    optimizer.zero_grad()\n",
        "    output = model(x)\n",
        "\n",
        "    loss = loss_fnc(output, target)\n",
        " #   loss.backward()\n",
        " #   optimizer.step()\n",
        "\n",
        "    preds = output[0] #.argmax() #dim=1)\n",
        "    correctas = (preds == target).sum()\n",
        "    total_correctas += correctas\n",
        "    total_muestras += target.shape[0]\n",
        "\n",
        "    accuracy = total_correctas / total_muestras\n",
        "\n",
        "    print('\\nEpoca:{} Loss:{:.2f}% Cor/Tot:{}/{} Accur:{:.2f}% X/Y/O:{}{}{}'.format(epoch, loss, total_correctas, total_muestras, 100*accuracy, x, target, preds), end='')\n",
        "\n",
        "  print('\\r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D3JdRVSMEhh",
        "outputId": "4736dfd2-2791-4ebb-c899-6500bedc9546"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoca:1 Loss:0.02% Cor/Tot:0.0/1.0 Accur:0.00% X/Y/O:tensor([50.])tensor([0.7660])0.6304581165313721\n",
            "Epoca:1 Loss:0.09% Cor/Tot:0.0/2.0 Accur:0.00% X/Y/O:tensor([19.])tensor([0.3256])0.6304581165313721\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/3.0 Accur:0.00% X/Y/O:tensor([83.])tensor([0.9925])0.6304581165313721\n",
            "Epoca:1 Loss:0.98% Cor/Tot:0.0/4.0 Accur:0.00% X/Y/O:tensor([262.])tensor([-0.9903])0.0014332126593217254\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/5.0 Accur:0.00% X/Y/O:tensor([121.])tensor([0.8572])0.5971532464027405\n",
            "Epoca:1 Loss:0.14% Cor/Tot:0.0/6.0 Accur:0.00% X/Y/O:tensor([88.])tensor([0.9994])0.6304581165313721\n",
            "Epoca:1 Loss:0.06% Cor/Tot:0.0/7.0 Accur:0.00% X/Y/O:tensor([125.])tensor([0.8192])0.5796301960945129\n",
            "Epoca:1 Loss:0.18% Cor/Tot:0.0/8.0 Accur:0.00% X/Y/O:tensor([335.])tensor([-0.4226])0.0012214583111926913\n",
            "Epoca:1 Loss:0.02% Cor/Tot:0.0/9.0 Accur:0.00% X/Y/O:tensor([51.])tensor([0.7771])0.6304581165313721\n",
            "Epoca:1 Loss:0.03% Cor/Tot:0.0/10.0 Accur:0.00% X/Y/O:tensor([54.])tensor([0.8090])0.6304581165313721\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/11.0 Accur:0.00% X/Y/O:tensor([82.])tensor([0.9903])0.6304581165313721\n",
            "Epoca:1 Loss:0.95% Cor/Tot:0.0/12.0 Accur:0.00% X/Y/O:tensor([257.])tensor([-0.9744])0.0014858171343803406\n",
            "Epoca:1 Loss:0.12% Cor/Tot:0.0/13.0 Accur:0.00% X/Y/O:tensor([76.])tensor([0.9703])0.6304581165313721\n",
            "Epoca:1 Loss:0.04% Cor/Tot:0.0/14.0 Accur:0.00% X/Y/O:tensor([56.])tensor([0.8290])0.6304581165313721\n",
            "Epoca:1 Loss:0.11% Cor/Tot:0.0/15.0 Accur:0.00% X/Y/O:tensor([17.])tensor([0.2924])0.6304581165313721\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/16.0 Accur:0.00% X/Y/O:tensor([81.])tensor([0.9877])0.6304581165313721\n",
            "Epoca:1 Loss:0.84% Cor/Tot:0.0/17.0 Accur:0.00% X/Y/O:tensor([246.])tensor([-0.9135])0.0016594913322478533\n",
            "Epoca:1 Loss:0.21% Cor/Tot:0.0/18.0 Accur:0.00% X/Y/O:tensor([333.])tensor([-0.4540])0.001222548889927566\n",
            "Epoca:1 Loss:0.14% Cor/Tot:0.0/19.0 Accur:0.00% X/Y/O:tensor([87.])tensor([0.9986])0.6304581165313721\n",
            "Epoca:1 Loss:0.14% Cor/Tot:0.0/20.0 Accur:0.00% X/Y/O:tensor([15.])tensor([0.2588])0.6304581165313721\n",
            "Epoca:1 Loss:0.08% Cor/Tot:0.0/21.0 Accur:0.00% X/Y/O:tensor([116.])tensor([0.8988])0.6153167486190796\n",
            "Epoca:1 Loss:0.97% Cor/Tot:0.0/22.0 Accur:0.00% X/Y/O:tensor([259.])tensor([-0.9816])0.0014632681850343943\n",
            "Epoca:1 Loss:0.12% Cor/Tot:0.0/23.0 Accur:0.00% X/Y/O:tensor([78.])tensor([0.9781])0.6304581165313721\n",
            "Epoca:1 Loss:0.02% Cor/Tot:0.0/24.0 Accur:0.00% X/Y/O:tensor([52.])tensor([0.7880])0.6304581165313721\n",
            "Epoca:1 Loss:0.31% Cor/Tot:0.0/25.0 Accur:0.00% X/Y/O:tensor([326.])tensor([-0.5592])0.0012270660372450948\n",
            "Epoca:1 Loss:0.19% Cor/Tot:0.0/26.0 Accur:0.00% X/Y/O:tensor([334.])tensor([-0.4384])0.0012219934724271297\n",
            "Epoca:1 Loss:0.05% Cor/Tot:0.0/27.0 Accur:0.00% X/Y/O:tensor([126.])tensor([0.8090])0.5747724175453186\n",
            "Epoca:1 Loss:0.09% Cor/Tot:0.0/28.0 Accur:0.00% X/Y/O:tensor([197.])tensor([-0.2924])0.01168135553598404\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/29.0 Accur:0.00% X/Y/O:tensor([80.])tensor([0.9848])0.6304581165313721\n",
            "Epoca:1 Loss:0.06% Cor/Tot:0.0/30.0 Accur:0.00% X/Y/O:tensor([193.])tensor([-0.2250])0.0164505522698164\n",
            "Epoca:1 Loss:0.05% Cor/Tot:0.0/31.0 Accur:0.00% X/Y/O:tensor([192.])tensor([-0.2079])0.017989860847592354\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/32.0 Accur:0.00% X/Y/O:tensor([16.])tensor([0.2756])0.6304581165313721\n",
            "Epoca:1 Loss:0.04% Cor/Tot:0.0/33.0 Accur:0.00% X/Y/O:tensor([55.])tensor([0.8192])0.6304581165313721\n",
            "Epoca:1 Loss:0.82% Cor/Tot:0.0/34.0 Accur:0.00% X/Y/O:tensor([245.])tensor([-0.9063])0.0016808209475129843\n",
            "Epoca:1 Loss:0.15% Cor/Tot:0.0/35.0 Accur:0.00% X/Y/O:tensor([202.])tensor([-0.3746])0.007936596870422363\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/36.0 Accur:0.00% X/Y/O:tensor([84.])tensor([0.9945])0.6304581165313721\n",
            "Epoca:1 Loss:0.12% Cor/Tot:0.0/37.0 Accur:0.00% X/Y/O:tensor([200.])tensor([-0.3420])0.009208221919834614\n",
            "Epoca:1 Loss:0.90% Cor/Tot:0.0/38.0 Accur:0.00% X/Y/O:tensor([251.])tensor([-0.9455])0.0015683859819546342\n",
            "Epoca:1 Loss:0.01% Cor/Tot:0.0/39.0 Accur:0.00% X/Y/O:tensor([185.])tensor([-0.0872])0.03459668532013893\n",
            "Epoca:1 Loss:0.10% Cor/Tot:0.0/40.0 Accur:0.00% X/Y/O:tensor([18.])tensor([0.3090])0.6304581165313721\n",
            "Epoca:1 Loss:0.10% Cor/Tot:0.0/41.0 Accur:0.00% X/Y/O:tensor([198.])tensor([-0.3090])0.010770013555884361\n",
            "Epoca:1 Loss:0.94% Cor/Tot:0.0/42.0 Accur:0.00% X/Y/O:tensor([256.])tensor([-0.9703])0.001497933641076088\n",
            "Epoca:1 Loss:0.15% Cor/Tot:0.0/43.0 Accur:0.00% X/Y/O:tensor([14.])tensor([0.2419])0.6304581165313721\n",
            "Epoca:1 Loss:0.28% Cor/Tot:0.0/44.0 Accur:0.00% X/Y/O:tensor([328.])tensor([-0.5299])0.0012256561312824488\n",
            "Epoca:1 Loss:0.12% Cor/Tot:0.0/45.0 Accur:0.00% X/Y/O:tensor([79.])tensor([0.9816])0.6304581165313721\n",
            "Epoca:1 Loss:0.04% Cor/Tot:0.0/46.0 Accur:0.00% X/Y/O:tensor([190.])tensor([-0.1736])0.021595057100057602\n",
            "Epoca:1 Loss:0.05% Cor/Tot:0.0/47.0 Accur:0.00% X/Y/O:tensor([128.])tensor([0.7880])0.5644282102584839\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/48.0 Accur:0.00% X/Y/O:tensor([194.])tensor([-0.2419])0.015064462088048458\n",
            "Epoca:1 Loss:0.11% Cor/Tot:0.0/49.0 Accur:0.00% X/Y/O:tensor([199.])tensor([-0.3256])0.009948753751814365\n",
            "Epoca:1 Loss:0.30% Cor/Tot:0.0/50.0 Accur:0.00% X/Y/O:tensor([327.])tensor([-0.5446])0.001226347521878779\n",
            "Epoca:1 Loss:0.06% Cor/Tot:0.0/51.0 Accur:0.00% X/Y/O:tensor([123.])tensor([0.8387])0.5887576937675476\n",
            "Epoca:1 Loss:0.11% Cor/Tot:0.0/52.0 Accur:0.00% X/Y/O:tensor([74.])tensor([0.9613])0.6304581165313721\n",
            "Epoca:1 Loss:0.89% Cor/Tot:0.0/53.0 Accur:0.00% X/Y/O:tensor([250.])tensor([-0.9397])0.0015847485046833754\n",
            "Epoca:1 Loss:0.16% Cor/Tot:0.0/54.0 Accur:0.00% X/Y/O:tensor([203.])tensor([-0.3907])0.00739122973755002\n",
            "Epoca:1 Loss:0.22% Cor/Tot:0.0/55.0 Accur:0.00% X/Y/O:tensor([332.])tensor([-0.4695])0.0012231266591697931\n",
            "Epoca:1 Loss:0.05% Cor/Tot:0.0/56.0 Accur:0.00% X/Y/O:tensor([127.])tensor([0.7986])0.5697078704833984\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/57.0 Accur:0.00% X/Y/O:tensor([201.])tensor([-0.3584])0.008540025912225246\n",
            "Epoca:1 Loss:0.04% Cor/Tot:0.0/58.0 Accur:0.00% X/Y/O:tensor([131.])tensor([0.7547])0.5472127199172974\n",
            "Epoca:1 Loss:0.06% Cor/Tot:0.0/59.0 Accur:0.00% X/Y/O:tensor([124.])tensor([0.8290])0.5842893123626709\n",
            "Epoca:1 Loss:0.17% Cor/Tot:0.0/60.0 Accur:0.00% X/Y/O:tensor([336.])tensor([-0.4067])0.001220940612256527\n",
            "Epoca:1 Loss:0.87% Cor/Tot:0.0/61.0 Accur:0.00% X/Y/O:tensor([249.])tensor([-0.9336])0.0016019776230677962\n",
            "Epoca:1 Loss:0.25% Cor/Tot:0.0/62.0 Accur:0.00% X/Y/O:tensor([330.])tensor([-0.5000])0.0012243458768352866\n",
            "Epoca:1 Loss:0.93% Cor/Tot:0.0/63.0 Accur:0.00% X/Y/O:tensor([254.])tensor([-0.9613])0.0015240228967741132\n",
            "Epoca:1 Loss:0.14% Cor/Tot:0.0/64.0 Accur:0.00% X/Y/O:tensor([91.])tensor([0.9998])0.6304581165313721\n",
            "Epoca:1 Loss:0.38% Cor/Tot:0.0/65.0 Accur:0.00% X/Y/O:tensor([322.])tensor([-0.6157])0.0012302141403779387\n",
            "Epoca:1 Loss:0.33% Cor/Tot:0.0/66.0 Accur:0.00% X/Y/O:tensor([325.])tensor([-0.5736])0.0012278101639822125\n",
            "Epoca:1 Loss:0.05% Cor/Tot:0.0/67.0 Accur:0.00% X/Y/O:tensor([129.])tensor([0.7771])0.5589248538017273\n",
            "Epoca:1 Loss:0.08% Cor/Tot:0.0/68.0 Accur:0.00% X/Y/O:tensor([115.])tensor([0.9063])0.6185176372528076\n",
            "Epoca:1 Loss:0.24% Cor/Tot:0.0/69.0 Accur:0.00% X/Y/O:tensor([331.])tensor([-0.4848])0.0012237244518473744\n",
            "Epoca:1 Loss:0.36% Cor/Tot:0.0/70.0 Accur:0.00% X/Y/O:tensor([323.])tensor([-0.6018])0.0012293836334720254\n",
            "Epoca:1 Loss:0.21% Cor/Tot:0.0/71.0 Accur:0.00% X/Y/O:tensor([207.])tensor([-0.4540])0.005678051151335239\n",
            "Epoca:1 Loss:0.40% Cor/Tot:0.0/72.0 Accur:0.00% X/Y/O:tensor([321.])tensor([-0.6293])0.00123107573017478\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/73.0 Accur:0.00% X/Y/O:tensor([122.])tensor([0.8480])0.5930432677268982\n",
            "Epoca:1 Loss:0.99% Cor/Tot:0.0/74.0 Accur:0.00% X/Y/O:tensor([264.])tensor([-0.9945])0.0014153792290017009\n",
            "Epoca:1 Loss:0.91% Cor/Tot:0.0/75.0 Accur:0.00% X/Y/O:tensor([252.])tensor([-0.9511])0.001552844070829451\n",
            "Epoca:1 Loss:0.98% Cor/Tot:0.0/76.0 Accur:0.00% X/Y/O:tensor([261.])tensor([-0.9877])0.0014427641872316599\n",
            "Epoca:1 Loss:0.03% Cor/Tot:0.0/77.0 Accur:0.00% X/Y/O:tensor([53.])tensor([0.7986])0.6304581165313721\n",
            "Epoca:1 Loss:0.08% Cor/Tot:0.0/78.0 Accur:0.00% X/Y/O:tensor([20.])tensor([0.3420])0.6304581165313721\n",
            "Epoca:1 Loss:0.12% Cor/Tot:0.0/79.0 Accur:0.00% X/Y/O:tensor([77.])tensor([0.9744])0.6304581165313721\n",
            "Epoca:1 Loss:0.04% Cor/Tot:0.0/80.0 Accur:0.00% X/Y/O:tensor([191.])tensor([-0.1908])0.019698791205883026\n",
            "Epoca:1 Loss:0.14% Cor/Tot:0.0/81.0 Accur:0.00% X/Y/O:tensor([89.])tensor([0.9998])0.6304581165313721\n",
            "Epoca:1 Loss:0.03% Cor/Tot:0.0/82.0 Accur:0.00% X/Y/O:tensor([189.])tensor([-0.1564])0.023697728291153908\n",
            "Epoca:1 Loss:0.17% Cor/Tot:0.0/83.0 Accur:0.00% X/Y/O:tensor([204.])tensor([-0.4067])0.006897805258631706\n",
            "Epoca:1 Loss:0.27% Cor/Tot:0.0/84.0 Accur:0.00% X/Y/O:tensor([329.])tensor([-0.5150])0.0012249891879037023\n",
            "Epoca:1 Loss:0.09% Cor/Tot:0.0/85.0 Accur:0.00% X/Y/O:tensor([113.])tensor([0.9205])0.6232250332832336\n",
            "Epoca:1 Loss:0.20% Cor/Tot:0.0/86.0 Accur:0.00% X/Y/O:tensor([206.])tensor([-0.4384])0.006045802962034941\n",
            "Epoca:1 Loss:0.06% Cor/Tot:0.0/87.0 Accur:0.00% X/Y/O:tensor([23.])tensor([0.3907])0.6304581165313721\n",
            "Epoca:1 Loss:0.05% Cor/Tot:0.0/88.0 Accur:0.00% X/Y/O:tensor([130.])tensor([0.7660])0.5531892776489258\n",
            "Epoca:1 Loss:0.08% Cor/Tot:0.0/89.0 Accur:0.00% X/Y/O:tensor([118.])tensor([0.8829])0.6085019111633301\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/90.0 Accur:0.00% X/Y/O:tensor([85.])tensor([0.9962])0.6304581165313721\n",
            "Epoca:1 Loss:0.05% Cor/Tot:0.0/91.0 Accur:0.00% X/Y/O:tensor([58.])tensor([0.8480])0.6304581165313721\n",
            "Epoca:1 Loss:0.04% Cor/Tot:0.0/92.0 Accur:0.00% X/Y/O:tensor([57.])tensor([0.8387])0.6304581165313721\n",
            "Epoca:1 Loss:0.02% Cor/Tot:0.0/93.0 Accur:0.00% X/Y/O:tensor([187.])tensor([-0.1219])0.02860480733215809\n",
            "Epoca:1 Loss:0.09% Cor/Tot:0.0/94.0 Accur:0.00% X/Y/O:tensor([112.])tensor([0.9272])0.6252047419548035\n",
            "Epoca:1 Loss:0.14% Cor/Tot:0.0/95.0 Accur:0.00% X/Y/O:tensor([90.])tensor([1.])0.6304581165313721\n",
            "Epoca:1 Loss:0.92% Cor/Tot:0.0/96.0 Accur:0.00% X/Y/O:tensor([253.])tensor([-0.9563])0.0015380724798887968\n",
            "Epoca:1 Loss:0.13% Cor/Tot:0.0/97.0 Accur:0.00% X/Y/O:tensor([86.])tensor([0.9976])0.6304581165313721\n",
            "Epoca:1 Loss:0.99% Cor/Tot:0.0/98.0 Accur:0.00% X/Y/O:tensor([263.])tensor([-0.9925])0.0014240910531952977\n",
            "Epoca:1 Loss:0.09% Cor/Tot:0.0/99.0 Accur:0.00% X/Y/O:tensor([114.])tensor([0.9135])0.6211640238761902\n",
            "Epoca:1 Loss:0.85% Cor/Tot:0.0/100.0 Accur:0.00% X/Y/O:tensor([247.])tensor([-0.9205])0.0016392876859754324\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/101.0 Accur:0.00% X/Y/O:tensor([22.])tensor([0.3746])0.6304581165313721\n",
            "Epoca:1 Loss:0.35% Cor/Tot:0.0/102.0 Accur:0.00% X/Y/O:tensor([324.])tensor([-0.5878])0.0012285817647352815\n",
            "Epoca:1 Loss:0.08% Cor/Tot:0.0/103.0 Accur:0.00% X/Y/O:tensor([196.])tensor([-0.2756])0.01269304659217596\n",
            "Epoca:1 Loss:0.02% Cor/Tot:0.0/104.0 Accur:0.00% X/Y/O:tensor([186.])tensor([-0.1045])0.031453486531972885\n",
            "Epoca:1 Loss:0.14% Cor/Tot:0.0/105.0 Accur:0.00% X/Y/O:tensor([92.])tensor([0.9994])0.6304581165313721\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/106.0 Accur:0.00% X/Y/O:tensor([120.])tensor([0.8660])0.6010950803756714\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/107.0 Accur:0.00% X/Y/O:tensor([21.])tensor([0.3584])0.6304581165313721\n",
            "Epoca:1 Loss:0.08% Cor/Tot:0.0/108.0 Accur:0.00% X/Y/O:tensor([117.])tensor([0.8910])0.611980140209198\n",
            "Epoca:1 Loss:0.97% Cor/Tot:0.0/109.0 Accur:0.00% X/Y/O:tensor([260.])tensor([-0.9848])0.0014527762541547418\n",
            "Epoca:1 Loss:0.81% Cor/Tot:0.0/110.0 Accur:0.00% X/Y/O:tensor([244.])tensor([-0.8988])0.0017033572075888515\n",
            "Epoca:1 Loss:0.96% Cor/Tot:0.0/111.0 Accur:0.00% X/Y/O:tensor([258.])tensor([-0.9781])0.0014742729254066944\n",
            "Epoca:1 Loss:0.18% Cor/Tot:0.0/112.0 Accur:0.00% X/Y/O:tensor([205.])tensor([-0.4226])0.006450944114476442\n",
            "Epoca:1 Loss:0.86% Cor/Tot:0.0/113.0 Accur:0.00% X/Y/O:tensor([248.])tensor([-0.9272])0.0016201401595026255\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/114.0 Accur:0.00% X/Y/O:tensor([119.])tensor([0.8746])0.6048757433891296\n",
            "Epoca:1 Loss:0.11% Cor/Tot:0.0/115.0 Accur:0.00% X/Y/O:tensor([75.])tensor([0.9659])0.6304581165313721\n",
            "Epoca:1 Loss:0.94% Cor/Tot:0.0/116.0 Accur:0.00% X/Y/O:tensor([255.])tensor([-0.9659])0.0015106558566913009\n",
            "Epoca:1 Loss:0.03% Cor/Tot:0.0/117.0 Accur:0.00% X/Y/O:tensor([188.])tensor([-0.1392])0.026027150452136993\n",
            "Epoca:1 Loss:0.07% Cor/Tot:0.0/118.0 Accur:0.00% X/Y/O:tensor([195.])tensor([-0.2588])0.013816574588418007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8qzs7GbNtXv",
        "outputId": "21bf7bf5-c469-43f0-9c43-0fe573aba3d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}